{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#156.11assignment.py\n",
    "# This code was written in collboration with \n",
    "#Yoel, Skye, and group members of CS156 Facebook chat.\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This function reads the data.\n",
    "\n",
    "def upload_files(your_path):\n",
    "    file_list = glob.glob(os.path.join(os.getcwd(), your_path))\n",
    "    \n",
    "    corpus_name =[]\n",
    "    \n",
    "    for file_path in file_list:\n",
    "        with open(file_path) as f_input:\n",
    "            corpus_name.append(f_input.read())\n",
    "    return corpus_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I open my data and split into language train sets and test set.\n",
    "#notice the location of the folders on your computer!\n",
    "train_corpus = upload_files(\"symbol/language-training*\")\n",
    "test_corpus = upload_files(\"symbol/language-test*\")\n",
    "\n",
    "data_input_A = train_corpus[:30]\n",
    "data_input_B = train_corpus[30:60]\n",
    "data_input_C = train_corpus[60:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "&lt;Table length=7&gt;\n",
       "<table id=\"table4438209104\" class=\"table-striped table-bordered table-condensed\">\n",
       "<thead><tr><th>A</th><th>e</th><th>g</th><th>k</th><th>o</th><th>p</th><th>t</th></tr></thead>\n",
       "<thead><tr><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th><th>float64</th></tr></thead>\n",
       "<tr><td>0.183970856102</td><td>0.0564663023679</td><td>0.220400728597</td><td>0.0418943533698</td><td>0.216757741348</td><td>0.0437158469945</td><td>0.23679417122</td></tr>\n",
       "<tr><td>0.0219224283305</td><td>0.185497470489</td><td>0.20741989882</td><td>0.035413153457</td><td>0.251264755481</td><td>0.0590219224283</td><td>0.239460370995</td></tr>\n",
       "<tr><td>0.294117647059</td><td>0.259259259259</td><td>0.276688453159</td><td>0.0305010893246</td><td>0.0457516339869</td><td>0.0152505446623</td><td>0.078431372549</td></tr>\n",
       "<tr><td>0.0486486486486</td><td>0.0378378378378</td><td>0.0864864864865</td><td>0.52972972973</td><td>0.108108108108</td><td>0.0972972972973</td><td>0.0918918918919</td></tr>\n",
       "<tr><td>0.304435483871</td><td>0.306451612903</td><td>0.0443548387097</td><td>0.0221774193548</td><td>0.25</td><td>0.0241935483871</td><td>0.0483870967742</td></tr>\n",
       "<tr><td>0.0346534653465</td><td>0.10396039604</td><td>0.113861386139</td><td>0.049504950495</td><td>0.113861386139</td><td>0.465346534653</td><td>0.118811881188</td></tr>\n",
       "<tr><td>0.267489711934</td><td>0.32304526749</td><td>0.0555555555556</td><td>0.0185185185185</td><td>0.0720164609053</td><td>0.022633744856</td><td>0.240740740741</td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Table length=7>\n",
       "       A               e        ...        p               t       \n",
       "    float64         float64     ...     float64         float64    \n",
       "--------------- --------------- ... --------------- ---------------\n",
       " 0.183970856102 0.0564663023679 ... 0.0437158469945   0.23679417122\n",
       "0.0219224283305  0.185497470489 ... 0.0590219224283  0.239460370995\n",
       " 0.294117647059  0.259259259259 ... 0.0152505446623  0.078431372549\n",
       "0.0486486486486 0.0378378378378 ... 0.0972972972973 0.0918918918919\n",
       " 0.304435483871  0.306451612903 ... 0.0241935483871 0.0483870967742\n",
       "0.0346534653465   0.10396039604 ...  0.465346534653  0.118811881188\n",
       " 0.267489711934   0.32304526749 ...  0.022633744856  0.240740740741"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def MarkovChain(data_input):\n",
    "    #\"Using python, build a Markov model for each of the languages.\"\n",
    "    #This function takes in a training \n",
    "    #corpus and outputs a table transition matrix for that language\n",
    "    #stores count of how many times \n",
    "    #letter i has been followed by letter j in nested loop\n",
    "    #then normalizes those values to set as probabilities\n",
    "\n",
    "    # this pulls out the list of our symbols in the data\n",
    "    letters = list(set(data_input[2])) \n",
    "    # initializes empty matrix\n",
    "    prob_matrix = np.zeros((len(letters),len(letters)))  \n",
    "    \n",
    "    for s in range(len(data_input)):\n",
    "        for ind in range(len(data_input[s])-1):\n",
    "            for i in range(len(letters)):\n",
    "                if data_input[s][ind] == letters[i]:\n",
    "                    for j in range(len(letters)):\n",
    "                        if data_input[s][ind+1] == letters[j]:\n",
    "                            prob_matrix[i][j] +=1\n",
    "    \n",
    "    #normalizes the matrix:\n",
    "    prob_matrix = prob_matrix / prob_matrix.sum(axis=1)[:,None]\n",
    "    Markov_Model = Table(prob_matrix, names = letters) #makes a pretty table\n",
    "    return Markov_Model #returns the table\n",
    "\n",
    "\n",
    "MarkovChain(data_input_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This function returns the probability of a \n",
    "#particular state shift (from i to j) given\n",
    "#a probability transition matrix for a language. \n",
    "#Note this is for one singular state change.\n",
    "\n",
    "def prob_of_letter(i,j,Transition): #Reads transition \n",
    "    #matrix to return probability that state j comes after i\n",
    "    \n",
    "    letter_dict={}\n",
    "    letters = ['A', 'e', 'g', 'k', 'o','p', 't']\n",
    "    for w in range(len(letters)):\n",
    "        letter_dict[letters[w]]= w\n",
    "    return Transition[letter_dict[i]-1][letter_dict[j]-1]\n",
    "    \n",
    "\n",
    "## This function returns the probability of \n",
    "#a string given a language  by looping through the string\n",
    "#and returning the product of all the probabilities of each transition\n",
    "\n",
    "def prob_of_string_language(string,data_input_language):\n",
    "    probs=[]\n",
    "    for i in range(len(string)-1):\n",
    "        probs.append(prob_of_letter(string[i],string[i+1],MarkovChain(data_input_language)))\n",
    "        #print string[i], string[i+1], len(string), i+1\n",
    "    prob_of_lang = np.prod(np.array(probs))\n",
    "    return prob_of_lang\n",
    "\n",
    "## this uses Bayes to calculate P(language|string) because P(language|str) \n",
    "#is proportional to P(str|language)\n",
    "#P(language model) = 1/3 for all strings and P(str) is constant as well.\n",
    "#P(language) and P(str) are the same for all languages given a string \n",
    "#so we can ignore them for classification\n",
    "## then normalize the probabilities later to get \n",
    "#the true probabilities because they must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test corpus classes are: ['B', 'B', 'B', 'C', 'B', 'C', 'B', 'C', 'C', 'B']\n",
      "posteriors:  [(0, [1.8820968256445955e-23, 0.99773015563263934, 0.0022698443673607239]), (1, [1.983285451706237e-06, 0.99267751060303477, 0.0073205061115135736]), (2, [1.7174082442274626e-08, 0.97236428248036078, 0.027635700345556694]), (3, [2.1121792914289608e-16, 0.016788337856251539, 0.98321166214374833]), (4, [3.7202187827210293e-07, 0.99999962313990898, 4.8382127733647256e-09]), (5, [0.014989848072646026, 2.1126625049776285e-21, 0.98501015192735397]), (6, [2.1584307033728302e-11, 0.99999991590289605, 8.4075519620014532e-08]), (7, [2.8512714218486112e-05, 9.2281792636093108e-22, 0.99997148728578156]), (8, [3.8721822874800726e-06, 9.8316490087838393e-22, 0.99999612781771252]), (9, [1.9200444644530564e-26, 0.99478362451315794, 0.0052163754868420715])]\n"
     ]
    }
   ],
   "source": [
    "## Produce results:\n",
    "\n",
    "classes = []\n",
    "posteriors=[]\n",
    "\n",
    "for i in range(len(test_corpus)):\n",
    "    # probability that the ith string in test corpus is language A:\n",
    "    p_A = prob_of_string_language(test_corpus[i], data_input_A)\n",
    "\n",
    "    # probability that the ith string in test corpus is language B:\n",
    "    p_B = prob_of_string_language(test_corpus[i], data_input_B)\n",
    "    \n",
    "    # probability that the ith string in test corpus is language B:\n",
    "    p_C = prob_of_string_language(test_corpus[i], data_input_C)\n",
    "\n",
    "    # construct classes list:\n",
    "    if max(p_A,p_B,p_C) == p_A:\n",
    "        classes.append('A')\n",
    "    elif max(p_A,p_B,p_C) == p_B:\n",
    "        classes.append('B')\n",
    "    elif max(p_A,p_B,p_C) == p_C:\n",
    "        classes.append('C')\n",
    "    \n",
    "    #construct posteriors list:\n",
    "    p_sum = p_A + p_B + p_C\n",
    "    posteriors.append((i,[p_A/p_sum,p_B/p_sum,p_C/p_sum]))\n",
    "    \n",
    "print 'test corpus classes are:', classes\n",
    "print 'posteriors: ', posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import scipy.io.wavfile\n",
    "import math\n",
    "import numpy as np\n",
    "from astropy.table import Table, Column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation of the model, and code of the initialization part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------- transition matrix: ------------------------------\n",
      "[0.9, 0.05, 0.05] \n",
      "[0.05, 0.9, 0.05] \n",
      "[0.05, 0.05, 0.9]\n",
      "-------------------------------------------- All sufficient data: ------------------------------\n",
      "Emission probabilities for speaker 1 : \n",
      "[(0.14034702489309211, 'A'), (0.19906276573952217, 'o'), (0.30698416234334097, 'e'), (0.129385515085984, 't'), (0.15245712458951835, 'p'), (0.02161575655301555, 'g'), (0.050147650795526924, 'k')] \n",
      "\n",
      "Emission probabilities for speaker 2 : \n",
      "[(0.10988290847925104, 'A'), (0.32719556494921564, 'o'), (0.091358085709219508, 'e'), (0.16935170474266648, 't'), (0.091970018754579483, 'p'), (0.015380496669967146, 'g'), (0.19486122069510067, 'k')] \n",
      "\n",
      "Emission probabilities for speaker 3 : \n",
      "[(0.029102635428063885, 'A'), (0.33084252009064474, 'o'), (0.11511233232423151, 'e'), (0.046077317609007726, 't'), (0.45387840490868364, 'p'), (0.0062192767054857125, 'g'), (0.018767512933882759, 'k')] \n",
      "\n",
      "----------------------------------------------- HMMModel: ------------------------------------\n",
      "\n",
      "Loading obsreved data and identifying probabilities of speakers per each phonem:\n",
      "\n",
      "\n",
      "The first speaker chosen is: Speaker_2. \n",
      "\n",
      "The transition probabilites, and emission probabilities of the first state / speaker randomely chosen are: \n",
      "\n",
      "[(0.10988290847925104, 'A'), (0.32719556494921564, 'o'), (0.091358085709219508, 'e'), (0.16935170474266648, 't'), (0.091970018754579483, 'p'), (0.015380496669967146, 'g'), (0.19486122069510067, 'k')]\n",
      "first parameter: e\n",
      "\n",
      "EM is an iterative algorithm. It works by computing an initial estimate for the\n",
      "probabilities, then using those estimates to computing a better estimate, and so on,\n",
      "iteratively improving the probabilities that it learns.\n",
      "https://web.stanford.edu/~jurafsky/slp3/9.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "phonemes = [['A', 'o', 'e', 't', 'p', 'g', 'k'],\n",
    "['A', 'o', 'e', 't', 'p', 'g', 'k'],['A', 'o', 'e', 't', 'p', 'g', 'k'],\n",
    "['A', 'o', 'e', 't', 'p', 'g', 'k'],['A', 'o', 'e', 't', 'p', 'g', 'k'],\n",
    "['A', 'o', 'e', 't', 'p', 'g', 'k'],['A', 'o', 'e', 't', 'p', 'g', 'k']]\n",
    "\n",
    "#initializing random emissions probabilities:\n",
    "P_state_1_per_speaker = .3\n",
    "emissions = {}\n",
    "all_emissions = []\n",
    "for i in range(3):\n",
    "\tname = \"P_phonemes_emission_{}\".format(i+1)\n",
    "\t# print name\n",
    "\t#nums here are samples from dirichlet that are 2d list:\n",
    "\tnums = np.random.dirichlet(np.ones(7),size=1)\n",
    "\t#flatten the list with sum:\n",
    "\tnums = sum(nums)\n",
    "\t# print nums, \"sum to:\" ,sum(nums) \n",
    "    #sanity check: all nums sum to one because they are derives \n",
    "    #from Dirichletm which is a pdf of pdfs, \n",
    "\t#so sampling from it actually samples probabilites.\n",
    "\temissions[name] = nums\n",
    "\tall_emissions.append(emissions[name])\n",
    "\n",
    "\"\"\"\n",
    "Transition Matrix: \n",
    "notice the uniform prioir for the two other speakers: \n",
    "no one is more aggresive than the other and so they are equally likely to \n",
    "cut the speaker.\n",
    "\"\"\"\n",
    "Speaker_1 = [.9,.05,.05]\n",
    "Speaker_2 = [.05,.9,.05]\n",
    "Speaker_3 = [.05,.05,.9]\n",
    "\n",
    "\n",
    "transition_matrix = [Speaker_1, \n",
    "\t\t\t\t\t Speaker_2,\n",
    "\t\t\t\t\t Speaker_3]\n",
    "\n",
    "print \"-------------------------------------------- transition matrix: ------------------------------\"\n",
    "print transition_matrix[0], '\\n' ,transition_matrix[1], '\\n' , transition_matrix[2]\n",
    "\n",
    "print \"-------------------------------------------- All sufficient data: ------------------------------\"\n",
    "# Couple phonemes with probabilites, and craete \n",
    "#a dict with speakers as keys for O(1) access:\n",
    "speakers = ['Speaker_1','Speaker_2','Speaker_3']\n",
    "t = 1\n",
    "speakers_info = {}\n",
    "for i,j,speaker in zip(all_emissions, phonemes, speakers):\n",
    "\tphonemes_probs = zip(i,j)\n",
    "\tprint \"Emission probabilities for speaker {} : \\n\".format(t),phonemes_probs, \"\\n\"\n",
    "\tspeakers_info[speaker] = phonemes_probs\n",
    "\tt+=1\n",
    "\n",
    "\n",
    "# probability of 'everything', i.e. the joint probability of O,H:\n",
    "# P(O,H) = P(H_1) \\prod_t P(H_t | H_t-1) P(O_t | H_t)\n",
    "\n",
    "\n",
    "print \"----------------------------------------------- HMMModel: ------------------------------------\"\n",
    "print\"\"\"\n",
    "Loading obsreved data and identifying \n",
    "probabilities of speakers per each phonem:\n",
    "\"\"\"\n",
    "\n",
    "PATH = \"speaker.2*\" #notice that the symbol file's \n",
    "#folder \"symbol\" should be in the same folder as this py file.\n",
    "import os, glob\n",
    "joined_files = glob.glob(os.path.join(os.getcwd(),PATH))\n",
    "\n",
    "for each_file in joined_files:\n",
    "\t# open the file and read the text:\n",
    "\twith open(each_file) as f:\n",
    "\t\ttext = f.read()\n",
    "\t\t#create a list of tuples with file name and the raw text:\n",
    "\t\tobserved_data = text\n",
    "\n",
    "# HMMModel:\n",
    "# 1. Generage the random speaker:\n",
    "import random\n",
    "first_to_speak = random.choice(speakers_info.keys())\n",
    "\n",
    "print \"\"\"\n",
    "The first speaker chosen is: {}. \\n\n",
    "The transition probabilites, and emission probabilities \n",
    "of the first state / speaker randomely chosen are: \n",
    "\\n\"\"\".format(first_to_speak), speakers_info[first_to_speak]\n",
    "\n",
    "# E. Given our parameters, can we compute how likely the hidden states are?\n",
    "first_param = observed_data[0]\n",
    "print \"first parameter:\", first_param\n",
    "# P(first_to_speak, first_param) =\n",
    "#P_state_1_per_speaker i.e. .33 * P(H_t | H_t-1) * P(O_t | H_t)\n",
    "#since this is the first state, we don't need to \n",
    "#consider the state before (i.e. the transition would just be 1)\n",
    "\n",
    "#prob_first_OandH = \n",
    "#P_state_1_per_speaker * [(num,_) for i in speakers_info[first_to_speak] if i is first_param]\n",
    "\n",
    "\n",
    "print \"\"\"\n",
    "EM is an iterative algorithm. It works by computing an initial estimate for the\n",
    "probabilities, then using those estimates to computing a better estimate, and so on,\n",
    "iteratively improving the probabilities that it learns.\n",
    "https://web.stanford.edu/~jurafsky/slp3/9.pdf\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction of states using HMMLearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function distribute_covar_matrix_to_match_covariance_type is deprecated; The function distribute_covar_matrix_to_match_covariance_typeis deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "/Users/oba2311/anaconda2/lib/python2.7/site-packages/sklearn/utils/deprecation.py:77: DeprecationWarning: Function log_multivariate_normal_density is deprecated; The function log_multivariate_normal_density is deprecated in 0.18 and will be removed in 0.20.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction: [2 0 2 2 2 2 2 1 2 2 2 2 0 2 0 0 0 0 0 0 0 2 0 0 0 0 2 0 0 0 0 0 0 2 2 1 1\n",
      " 0 1 1 1 0 1 0 0 0 0 0 2 0 0 0 0 0 0 2 2 2 2 0 0 0 0 0 0 0 2 2 0 2 0 0 0 0\n",
      " 0 0 0 2 0 0 0 2 0 0 2 0 0 0 0 0 2 2 0 2 2 2 2 2 0 2 2 2 0 0 2 0 0 0 0 2 1\n",
      " 0 1 0 0 1 0 1 0 1 0 0 0 1 2 2 2 1 2 2 2 2 0 0 0 0 1 1 1 1 0 0 2 2 2 2 2 0\n",
      " 2 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 2 0 2 2 0 2 0 2 1 2 1 2 2 0 0 2 0 0 0 0 0\n",
      " 2 2 2 2 0 1 1 1 1 2 1 0 2 2 2 0 2 0 2 2 0 1 0 1 0 1 1 0 0 1 1 1 0 0 0 1 0\n",
      " 0 1 1 1 0 1 1 0 0 1 1 1 0 0 0 1 0 1 1 0 1 0 0 2 2 0 0 0 0 1 0 1 0 0 1 1 0\n",
      " 1 1 1 0 2 2 0 2 2 2 2 0 2 2 2 2 0 2 0 1 0 0 2 1 0 0 0 2 0 2 1 2 2 0 1 2 2\n",
      " 0 0 1 0 0 1 1 2 1 1 0 0 0 0 0 1 0 0 1 2 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 1 1\n",
      " 0 0 1 1 1 1 2 1 2 0 2 0 2 0 0 2 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 2 2 0 1 0\n",
      " 0 0 0 1 2 2 0 0 2 0 0 2 1 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 0 2 0 2 2 2 2\n",
      " 0 0 2 0 1 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 2 0 0 0\n",
      " 0 0 0 0 0 0 0 2 0 1 1 0 0 0 1 0 2 0 0 2 2 2 2 2 2 2 2 2 2 1 0 2 1 2 0 0 1\n",
      " 0 1 0 0 2 0 2 2 2 2 2 2 2 2 2 2 0 2 2 2 0 0 1 1 0 0 0 0 0 0 2 2 2 2 2 0 2\n",
      " 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 2 2 1 2 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 1 2 1 2 2 2 2 2 0 2 2 2 1 2 0 2 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 1 1 1 0 2 0 0 1 0 1 0 0 0 0 0 1 1 0 0 2 2 0 1 0 0 0 0 2 1 2\n",
      " 0 0 2 2 2 0 2 2 1 0 0 1 0 2 2 1 2 2 0 0 0 0 2 0 0 0 0 0 2 0 0 0 2 0 0 2 0\n",
      " 0 0 0 1 1 0 0 0 2 2 2 0 0 1 1 0 0 0 0 0 0 0 2 1 1 0 2 0 1 0 0 0 2 2 2 2 2\n",
      " 2 0 2 0 0 2 2 0 1 2 2 0 0 1 2 1 0 0 0 0 1 1 0 1 0 0 1 0 2 2 2 0 0 0 2 0 1\n",
      " 0 0 1 0 0 2 0 1 0 0 2 0 1 0 0 0 2 0 2 0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0\n",
      " 0 2 0 0 1 0 0 0 0 0 0 0 1 0 0 0 1 0 0 2 2 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 1 0\n",
      " 0 2 2 2 2 2 2 2 0 2 2 2 2 0 2 2 2 0 2 0 0 0 1 1 0 1 0 1 1 0 2 2 2 2 2 2 0\n",
      " 1 2 1 0 0 1 1 1 0 0 1 0 1 1 1 0 0 1 2 0 0 1 1 1 0 0 0 0 1 1 0 0 2 2 0 0 0\n",
      " 2 2 2 0 0 0 2 0 0 2 2 2 2 2 0 2 0 0 0 0 1 0 0 0 0 0 0 0 2 2 2 2 2 2 0 0 0\n",
      " 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a1cf8b690>]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIRo8AvIhIxCvwiIhGjwC8iEjH/H8sxrYDxDZS9AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x109ef0cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "PATH = \"speaker.2*\" #notice that the symbol \n",
    "#file's folder \"symbol\" should be in the same folder as this py file.\n",
    "import os, glob\n",
    "joined_files = glob.glob(os.path.join(os.getcwd(),PATH))\n",
    "\n",
    "for each_file in joined_files:\n",
    "\t# open the file and read the text:\n",
    "\twith open(each_file) as f:\n",
    "\t\ttext = f.read()\n",
    "\t\t#create a list of tuples with file name and the raw text:\n",
    "\t\tobserved_data = text\n",
    "\n",
    "#convert the string to nums:\n",
    "chars_as_nums = []\n",
    "for i in text:\n",
    "\tnum = ord(i)\n",
    "\tchars_as_nums.append(num)\n",
    "\n",
    "import numpy as np\n",
    "X = np.asarray(chars_as_nums).reshape(-1,1)\n",
    "import numpy as np\n",
    "states = 'sp1','sp2','sp3'\n",
    "SEQUENCE = (states,text)\n",
    "\n",
    "from hmmlearn import hmm\n",
    "\n",
    "#Using the HMM with the MAP algorithm: Maximum \n",
    "remodel = hmm.GaussianHMM(n_components=3, covariance_type=\"full\", n_iter=100,algorithm=\"map\")\n",
    "#\"MAP: maximum a posteriori probability \n",
    "#(MAP) estimate is an estimate of an unknown quantity, \n",
    "#that equals the mode of the posterior distribution. \"\n",
    "remodel.fit(X)  \n",
    "#NOTICE: the model predicts the most likely speaker at a point, \n",
    "#but unfortunately not the posterior (i.e. the likelihood of each speaker,\n",
    "#given the former step (transmission prob.) and the phoneme(emission prob.))\n",
    "Z2 = remodel.predict(X)\n",
    "import matplotlib.pyplot as plt\n",
    "print 'prediction:' ,Z2\n",
    "plt.plot(Z2,'o', markersize=.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
